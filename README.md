# Powerpoint-rejection
#This is a simple image rejection tool that I wrote during my three month internship in 2023. 
**Context**
The company that I was interning at had large amounts of internal meeting recordings that they wanted to robotically transcribe. For the most part, this worked well. Unfortunately, there were a few edge cases that would cause issues, for example if the presentee "clicked through" the  presentation instead of presenting in full screen, or when they checked their emails during a presentation break. To reject these and other images that were irrelevant to the transcription, I wrote the following code.
**Description**
The code first installs all relevant imports, and then checks the CUDA version. The next cell defines the function that is used to classify the image which is later passed forward from a different cell. The image is classified using OpenAIs CLIP large language model. I decided to use three different prompts to check if the given image is relevant or should be rejected, as these also rejected the image correctly with a accuracy of about 85% in cases where the image was different from the three prompts (e.g. a screenshot of an email main page). The function returns True if the image should be kept and False if it should be rejected.
The next cell identifies the relevant image area to pass forward to the classification model. This is especially relevant in those cases where the presentation recording is not a simple full screen presentation (e.g. a presenter clicking through the powerpoint while a viewport shows their face), but there is still relevant presentation data that should be transcribed. This code uses OpenCV to identify the largest image area (which should _mostly_ be the relevant part of the image during a presentation) and calls the classify_image function on this image that I defined earlier. 
